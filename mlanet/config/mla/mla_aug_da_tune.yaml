BASE_TASK_CONFIG_PATH: habitat_extensions/config/vlnce_mla_v13.yaml
TRAINER_NAME: dagger # dagger, or recollect_trainer
SIMULATOR_GPU_IDS: [0]
TORCH_GPU_ID: 0
NUM_ENVIRONMENTS: 4
TENSORBOARD_DIR: data/tensorboard_dirs/mla_aug_da_tune
CHECKPOINT_FOLDER: data/checkpoints/mla_aug_da_tune
EVAL_CKPT_PATH_DIR: data/checkpoints/mla_aug_da_tune
RESULTS_DIR: data/checkpoints/mla_aug_da_tune/evals

EVAL:
  USE_CKPT_CONFIG: False
  SPLIT: val_seen
  EPISODE_COUNT: -1

IL:
  epochs: 4
  batch_size: 5
  lr: 2.5e-4
  use_iw: True
  inflection_weight_coef: 3.2
  load_from_ckpt: True
  ckpt_to_load: data/checkpoints/mla_aug_back2/ckpt.MLAPolicy.28.pth # REPLACE

  DAGGER:
    iterations: 10
    update_size: 5000
    p: 0.5
    preload_lmdb_features: False
    lmdb_features_dir: data/trajectories_dirs/mla_aug_da_tune/trajectories.lmdb

MODEL:
  policy_name: MLAPolicy

  INSTRUCTION_ENCODER:
    bidirectional: True
  PROGRESS_MONITOR:
    use: True
    alpha: 1.0
  PEAK_ATTENTION:
    use: True
    type: 1
    alpha: 0.4
    sigma: 0.6
    steps: 220000
    threashold: 1.0
  MLA:
    feature_drop: 0.25
  CLIP:
    rgb_level: -2
  SEQ2SEQ:
    encoder_prev_action: True
    decoder_prev_action: True
